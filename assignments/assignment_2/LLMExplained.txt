LLMs use a tokenizer to allow computers to interpret text in a numeric format, that is then translated into an embedding space to calculate the most likely next word to appear in the text. LLMs have been fine tuned to not only be next word predictors but also respond in a chat-like manner. Mixture of Experts fine tunes several different versions of LLMs to be able to perform different tasks much more effectively, creating different specialized LLMs. There is a router that routes the answer to the correct expert. Coding assistants can utilize LLMs as the backend to help programmers write code and explain code.
